i. Analyze the programs (environment.py and policy_iteration.py) and write/submit
a report. Also, capture two screenshots of the program execution and include
them in the report.

ii. In the program, the initial values of value function are zero, and the initial policy
follows uniform distribution. Change initial values to random values, and change
the initial policy to be normalized random values. (i.e. random probabilities and
their sum should be one) Observe the training process and include the analysis
in the report. Also, capture two screenshots of this modied program's execution
and include them in the report.

iii. With the original setting for value function and policy, consider the following
experiment. Note that there are already triangles at (3,2) and (2,3). Now add
one more triangle with reward=-1 at (3,4). Observe the training process and
include the analysis in the report. Also, capture two screenshots of this modied
program's execution and include them in the report.